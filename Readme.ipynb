{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32ecab3",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This project involves developing a robust image processing and machine learning pipeline for age classification using a dataset of face images. The system design includes several scripts and configurations to handle data loading, preprocessing, quality checking, augmentation, visualization, and model training. The key components and their functionalities are described below.\n",
    "\n",
    "##  System Design\n",
    "\n",
    "- `utils.py`: Contains utility functions that are commonly used across multiple scripts.\n",
    "\n",
    "- `explore_images.py`: Main script for loading the dataset, computing image quality metrics, checking image quality, and generating a CSV file with metadata.\n",
    "\n",
    "- `image_reader.py`: Provides functions to load images, compute image quality metrics, and check image quality based on predefined thresholds.\n",
    "\n",
    "- `image_processor.py`: Includes functions for processing images, such as sharpening, denoising, brightening, and enhancing texture. Also contains functions to ensure the processed images meet quality standards.\n",
    "\n",
    "- `process_images.py`: Script to apply image processing functions to the dataset and save the processed images.\n",
    "\n",
    "- `image_visualizer.py`: Provides functions for visualizing distributions of image quality metrics and saving the visualizations.\n",
    "\n",
    "- `visualize_image_information.py`: Main script to visualize image quality metrics using the functions in `image_visualizer.py`. Generates plots for various metrics and saves them to specified directories.\n",
    "\n",
    "- `australian_population.ipynb`: Jupyter notebook for analyzing Australian population distribution. Used to create a target distribution for resampling the dataset to match age demographics.\n",
    "\n",
    "- `resampling.ipynb`: Jupyter notebook for resampling the dataset based on the target age distribution. Performs both up-sampling and down-sampling to achieve the desired distribution.\n",
    "\n",
    "- `train_model.py`: Script to train a deep learning model for age classification. Includes data loading, model definition, training loop, and evaluation metrics.\n",
    "\n",
    "### Configuration Files\n",
    "\n",
    "The configuration files are stored in the configs directory. They specify various parameters for different scripts, such as paths to datasets, thresholds for quality metrics, and settings for data augmentation and model training.\n",
    "Directories\n",
    "\n",
    "- csv: Contains CSV files with metadata generated by explore_images.py.\n",
    "\n",
    "- processed_dataset: Directory where processed images are saved after applying image quality checks and enhancements.\n",
    "\n",
    "- resampled_dataset: Directory where resampled images are saved to match the target age distribution.\n",
    "\n",
    "### Detailed Component Descriptions\n",
    "\n",
    "#### utils.py\n",
    "\n",
    "- Contains utility functions for tasks such as reading configuration files, logging, and common data processing steps.\n",
    "\n",
    "#### explore_images.py\n",
    "\n",
    "- Reads a configuration file for parameters.\n",
    "- Loads images from the dataset directory.\n",
    "- Computes image quality metrics such as blurriness, noise, brightness, and resolution.\n",
    "- Checks the quality of images based on defined thresholds.\n",
    "- Generates a CSV file with metadata for all images.\n",
    "\n",
    "#### image_reader.py\n",
    "\n",
    "- load_dataset: Loads images and their corresponding age labels.\n",
    "- compute_images_quality_metrics: Computes quality metrics for each image.\n",
    "- check_images_quality: Checks image quality and flags low-quality images.\n",
    "\n",
    "#### image_processor.py\n",
    "\n",
    "- Functions to process images (e.g., sharpening, denoising, brightening).\n",
    "- Ensures processed images meet quality standards.\n",
    "\n",
    "#### process_images.py\n",
    "\n",
    "- Applies image processing functions to the dataset.\n",
    "- Saves processed images to the processed_dataset directory.\n",
    "\n",
    "#### image_visualizer.py\n",
    "\n",
    "- visualize_distribution: Creates histograms for various image quality metrics and saves the plots.\n",
    "\n",
    "#### visualize_image_information.py\n",
    "\n",
    "- Uses image_visualizer.py functions to generate and save plots for image quality metrics.\n",
    "- Reads metadata from a CSV file and creates visualizations.\n",
    "\n",
    "#### australian_population.ipynb\n",
    "\n",
    "- Analyzes Australian population distribution to create a target age distribution for resampling the dataset.\n",
    "\n",
    "#### resampling.ipynb\n",
    "\n",
    "- Performs resampling of the dataset to match the target age distribution.\n",
    "- Uses both up-sampling (data augmentation) and down-sampling techniques.\n",
    "\n",
    "#### train_model.py\n",
    "\n",
    "- Loads the dataset and splits it into training and validation sets.\n",
    "- Defines the age classification model.\n",
    "- Trains the model and evaluates its performance.\n",
    "- Saves the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621081b",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "### 1. Age Distribution\n",
    "\n",
    "![image](visualizations/original_image/age_distribution.png)\n",
    "\n",
    "This histogram represents the distribution of images across different ages. Here's an explanation of the key points:\n",
    "\n",
    "- X-axis (Age): The x-axis shows the age groups, ranging from 20 to 50 years.\n",
    "- Y-axis (Number of Images): The y-axis shows the number of images corresponding to each age group.\n",
    "- Insight: This histogram shows the distribution of the number of images across different age groups in the dataset. The dataset includes images labeled with ages ranging from 20 to 50. There is a noticeable peak around the age of 25 and a lower count of images in the higher age ranges like 45-50.\n",
    "\n",
    "### 2. Laplacian Variance Distribution\n",
    "\n",
    "![image](visualizations/original_image/laplacian_variance_distribution.png)\n",
    "\n",
    "- X-axis: Laplacian Variance\n",
    "- Y-axis: Number of Images\n",
    "- Insight: This histogram shows the distribution of the Laplacian variance values, which measure the sharpness of the images. A low variance indicates a blurry image. Most images have a low Laplacian variance, suggesting that there are many blurry images in the dataset.\n",
    "\n",
    "### 3. Mean Intensity Distribution\n",
    "\n",
    "![image](visualizations/original_image/mean_intensity_distribution.png)\n",
    "\n",
    "- X-axis: Mean Intensity\n",
    "- Y-axis: Number of Images\n",
    "- Insight: This histogram shows the distribution of the mean intensity values of the images. The mean intensity is a measure of the overall brightness of an image. Most images have a mean intensity between 50 and 150, suggesting that the dataset contains images with a wide range of lighting conditions.\n",
    "\n",
    "### 4. Standard Deviation Distribution\n",
    "\n",
    "![image](visualizations/original_image/standard_deviation_distribution.png)\n",
    "\n",
    "- X-axis: Standard Deviation\n",
    "- Y-axis: Number of Images\n",
    "- Insight: This histogram shows the distribution of the standard deviation of pixel intensities in the images. The standard deviation is a measure of the noise or texture in an image. Most images have a standard deviation between 40 and 80, indicating moderate noise levels.\n",
    "\n",
    "### Image Quality Metrics\n",
    "\n",
    "#### 1. Blurry Images\n",
    "\n",
    "Blurriness can be quantified using the variance of the Laplacian. The Laplacian operator highlights regions of rapid intensity change, and its variance is a measure of how much the intensity changes in the image.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "- **Laplacian:** The Laplacian is a second-order derivative operator that computes the sum of second-order derivatives in both the x and y directions.\n",
    "- **Variance of the Laplacian:** The variance of the Laplacian measures the spread of pixel intensity values after applying the Laplacian operator. Lower variance indicates less sharpness (i.e., more blurriness).\n",
    "\n",
    "#### 2. Noisy Images\n",
    "\n",
    "Noise in images can be quantified using the standard deviation of pixel intensity values. High noise levels usually lead to higher standard deviation due to the random fluctuations in pixel values.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "- **Standard Deviation:** Measures the amount of variation or dispersion of a set of values. Higher standard deviation indicates higher noise.\n",
    "\n",
    "#### 3. Low Resolution\n",
    "\n",
    "The number of pixels in the horizontal and vertical dimensions of the image.\n",
    "\n",
    "#### 4. Poor Lighting\n",
    "\n",
    "Poor lighting can be quantified using the mean intensity of the image. Images that are too dark or too bright will have mean intensity values close to 0 or 255, respectively.\n",
    "\n",
    "**Thresholds for Image Quality Metrics:**\n",
    "- **Laplacian Variance (Blurriness):**\n",
    "  - Too Low: $< 100$ (indicates significant blurriness)\n",
    "  - Too High: $> 1000$ (generally not an issue unless excessively high due to noise)\n",
    "- **Mean Intensity (Brightness):**\n",
    "  - Too Low: $< 50$ (indicates the image is too dark)\n",
    "  - Too High: $> 200$ (indicates the image is too bright)\n",
    "- **Standard Deviation (Noise):**\n",
    "  - Too Low: $< 10$ (indicates lack of texture or overly smooth images)\n",
    "  - Too High: $> 100$ (indicates significant noise)\n",
    "- **Resolution:**\n",
    "  - Typically, images with resolution less than a certain threshold (e.g., $100 \\times 100$ pixels) are considered low resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913905a",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "### 1. Too Blurry\n",
    "\n",
    "Technique: Sharpening\n",
    "\n",
    "- Unsharp Masking: Enhances the edges in the image by subtracting a blurred version of the image from the original image.\n",
    "- High-Pass Filtering: Emphasizes high-frequency components (edges) in the image.\n",
    "\n",
    "### 2. Too Noisy (High Laplacian Variance or High Standard Deviation)\n",
    "\n",
    "Technique: Denoising\n",
    "\n",
    "- Gaussian Blur: Reduces image noise and detail by applying a Gaussian filter.\n",
    "- Median Filtering: Reduces salt-and-pepper noise by replacing each pixel with the median value in its neighborhood.\n",
    "- Bilateral Filtering: Reduces noise while preserving edges.\n",
    "    \n",
    "### 3. Too Dark & Too Bright\n",
    "\n",
    "Technique: Brightness Adjustment\n",
    "\n",
    "- Histogram Equalization: Enhances the contrast of images by spreading out the most frequent intensity values.\n",
    "- Gamma Correction: Adjusts the brightness by applying a gamma value to the pixel values.\n",
    "    \n",
    "    \n",
    "### 4. Lack of Texture\n",
    "\n",
    "Technique: Texture Enhancement\n",
    "\n",
    "- High-Pass Filtering: Enhances textures and edges by removing low-frequency components.\n",
    "- Histogram Equalization: Enhances the contrast and can bring out textures.\n",
    "    \n",
    "### 5. Low Resolution\n",
    "\n",
    "Technique: Super-Resolution\n",
    "\n",
    "- Super-Resolution Techniques: Enhance the resolution of an image using machine learning models or interpolation methods.\n",
    "- Interpolation: Methods like bilinear or bicubic interpolation to increase image size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b59a719",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "The resampling process is a crucial part of ensuring that the dataset used for training machine learning models is balanced and representative of the target population distribution. The goal is to modify the dataset to match the desired distribution, which can help improve the model's performance and generalizability.\n",
    "\n",
    "### 1. Analyze the Target Distribution:\n",
    "- The target distribution, such as the 2021 Australian population distribution, provides the basis for how the dataset should be resampled.\n",
    "- This distribution is used to calculate the required number of images for each age group to ensure the dataset is balanced.\n",
    "\n",
    "![image](visualizations/australian_population_distribution.png)\n",
    "\n",
    "### 2. Calculate Required Images:\n",
    "- The number of required images for each age group is calculated based on the target distribution.\n",
    "- For example, if the dataset contains 20,000 images and the target distribution indicates that 7.1% of the population is aged 25 to 29, then approximately 1,420 images should represent this age group.\n",
    "\n",
    "### 3. Assess Current Distribution:\n",
    "- The current distribution of images across age groups is analyzed to determine the number of images currently available for each group.\n",
    "- This analysis helps identify any imbalances in the dataset.\n",
    "\n",
    "### 4. Determine Image Difference:\n",
    "- The difference between the required number of images and the current number of images is calculated for each age group.\n",
    "- Positive values indicate the need for more images (up-sampling), while negative values indicate an excess of images (down-sampling).\n",
    "\n",
    "### 5. Perform Up-sampling and Down-sampling:\n",
    "- Up-sampling: For age groups with fewer images than required, additional images are generated using data augmentation techniques. These techniques may include rotation, flipping, and color adjustment to create new, unique images from the existing ones.\n",
    "- Down-sampling: For age groups with more images than required, a random selection of images is removed to reduce the number to the desired level.\n",
    "\n",
    "### 6. Validate Resampling:\n",
    "- After the resampling process, the new distribution of images is validated against the target distribution to ensure the resampling process has achieved the desired balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23075165",
   "metadata": {},
   "source": [
    "## Model Development & Training and Evaluation\n",
    "\n",
    "The train_model.py script is designed to train a deep learning model for age classification using the SqueezeNet architecture. This script preprocesses the data, defines the model, trains it, and evaluates its performance using metrics like loss and AUC (Area Under the Curve).\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The data preparation involves:\n",
    "\n",
    "#### 1. Defining a Custom Dataset:\n",
    "- The AgeDataset class is used to load images from the resampled_dataset directory.\n",
    "- Images are labeled based on their subdirectory names, which correspond to the age group.\n",
    "\n",
    "#### 2. Applying Transformations:\n",
    "- Images are resized to 128x128 pixels.\n",
    "- Images are normalized using the mean and standard deviation of the ImageNet dataset.\n",
    "\n",
    "#### 3. Creating Data Loaders:\n",
    "- The dataset is split into training and validation sets (80% training, 20% validation).\n",
    "- Data loaders are created for both sets to facilitate batch processing during training.\n",
    "\n",
    "### Model Definition\n",
    "\n",
    "The AgeClassifier class defines the model architecture using the SqueezeNet model:\n",
    "\n",
    "- The final classification layer of SqueezeNet is replaced with a convolutional layer to output 31 classes, corresponding to ages 20 to 50.\n",
    "- The model is chosen specifically because its number of parameters does not exceed 1 million, making it suitable for deployment on edge devices.\n",
    "\n",
    "### Training Process\n",
    "\n",
    "The training process involves:\n",
    "\n",
    "#### 1. Defining Loss Function and Optimizer:\n",
    "- The CrossEntropyLoss function is used as the loss criterion.\n",
    "- The Adam optimizer is used for parameter updates.\n",
    "\n",
    "#### 2. Training Loop:\n",
    "- The model is trained for a specified number of epochs.\n",
    "- For each epoch, the model goes through a training phase and a validation phase.\n",
    "- Metrics such as loss and AUC are calculated and stored for each epoch.\n",
    "\n",
    "#### 3. Saving the Best Model:\n",
    "- The model weights that yield the best validation AUC are saved.\n",
    "\n",
    "#### 4. Parameter Count Check:\n",
    "- The script checks the number of parameters in the model and ensures it does not exceed 1 million. This is critical for deployment on edge devices where resources are limited.\n",
    "\n",
    "### Performance Visualization\n",
    "\n",
    "The script generates visualizations for the training and validation metrics:\n",
    "\n",
    "![image](visualizations/train_model.png)\n",
    "\n",
    "#### 1. Training and Validation Loss:\n",
    "- The left plot in the figure shows the training and validation loss over the epochs.\n",
    "- The training loss decreases steadily, indicating that the model is learning from the data.\n",
    "- The validation loss, however, shows some fluctuations and starts to increase slightly after a few epochs, suggesting potential overfitting.\n",
    "\n",
    "#### 2. Training and Validation AUC:\n",
    "- The right plot in the figure shows the training and validation AUC over the epochs.\n",
    "- The training AUC increases consistently, indicating improving model performance on the training set.\n",
    "- The validation AUC increases initially but then fluctuates, which again might suggest overfitting or variability in validation performance.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The model achieved the best validation AUC as indicated in the training logs. The generated plots provide a clear view of the model's learning process and highlight areas where improvements can be made, such as addressing potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c940648",
   "metadata": {},
   "source": [
    "## Model Packaging for C++ Deployment\n",
    "\n",
    "To hand over the trained age prediction model to a C++ developer for seamless integration into a C++ pipeline, follow these steps:\n",
    "\n",
    "### 1. Export the Trained Model:\n",
    "- Save the trained PyTorch model using the torch.save() function. This creates a .pth file containing the model's state_dict (weights and biases).\n",
    "\n",
    "### 2. Convert the Model to ONNX Format:\n",
    "- Convert the saved PyTorch model to ONNX (Open Neural Network Exchange) format using the torch.onnx.export() function. ONNX is a widely supported format for machine learning models, making it easier to integrate into various platforms, including C++.\n",
    "\n",
    "### 3. Prepare Preprocessing Scripts:\n",
    "- Create a Python script for image preprocessing and normalization. This script should include all the steps necessary to prepare input images for the model, such as resizing, normalization, and any other required transformations.\n",
    "\n",
    "### 4. Package the Model and Scripts:\n",
    "- Package the ONNX model file and the preprocessing scripts together. Ensure that all necessary dependencies are included and that the C++ developer has clear instructions on how to use these files.\n",
    "\n",
    "### 5. Provide Usage Instructions:\n",
    "- Write detailed instructions for the C++ developer, explaining how to load the ONNX model and use the preprocessing scripts. Include information on the expected input format and any required dependencies or environment setup.\n",
    "\n",
    "### 6. Integrate with C++ Pipeline:\n",
    "- Instruct the C++ developer to use an ONNX runtime (such as ONNX Runtime or TensorRT) to load and run the model. The preprocessing script can be used to prepare the images before passing them to the model for inference.\n",
    "\n",
    "## Steps for Using the Packaged Model in C++\n",
    "\n",
    "### 1. Load the ONNX Model:\n",
    "- Use an ONNX runtime library to load the ONNX model file. This will involve initializing the runtime and loading the model into memory.\n",
    "\n",
    "### 2. Preprocess Input Images:\n",
    "- Use the provided Python preprocessing script to prepare input images. This script should handle tasks like resizing, normalization, and any other required transformations.\n",
    "\n",
    "### 3. Run Inference:\n",
    "- Pass the preprocessed images to the ONNX model using the runtime library. Perform inference to obtain age predictions.\n",
    "\n",
    "### 4. Post-process Predictions:\n",
    "- Convert the model's output to meaningful age predictions. This may involve mapping the model's output to specific age groups.\n",
    "\n",
    "### 5. Integrate into C++ Application:\n",
    "- Integrate the entire process into the existing C++ pipeline, ensuring that the image preprocessing, model inference, and post-processing steps are all correctly implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999b1c5",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "### Potential Improvements to the Model\n",
    "\n",
    "#### 1. Model Architecture Enhancements:\n",
    "- Explore more advanced or efficient model architectures such as EfficientNet or MobileNetV3. These architectures may offer better performance or reduced computational requirements, which is crucial for deployment on edge devices.\n",
    "\n",
    "#### 2. Hyperparameter Optimization:\n",
    "- Conduct extensive hyperparameter tuning to optimize the learning rate, batch size, and other parameters. Techniques such as grid search or Bayesian optimization can be employed to find the best combination of hyperparameters.\n",
    "\n",
    "#### 3. Transfer Learning:\n",
    "- Utilize pre-trained models on larger datasets and fine-tune them on the age prediction dataset. Transfer learning can significantly improve model performance, especially with limited data.\n",
    "\n",
    "#### 4. Model Quantization:\n",
    "- Apply model quantization techniques to reduce the model size and increase inference speed on edge devices. Quantization-aware training can help in maintaining model accuracy while reducing computational requirements.\n",
    "\n",
    "### Potential Improvements to the Pipeline\n",
    "\n",
    "#### 1. Automated Data Pipeline:\n",
    "- Develop an automated pipeline for data preprocessing, augmentation, and quality assessment. This would streamline the data preparation process and ensure consistent data quality.\n",
    "\n",
    "#### 2. Real-time Inference:\n",
    "- Optimize the pipeline for real-time inference, enabling the model to make predictions with minimal latency. This is particularly important for applications where timely predictions are critical.\n",
    "\n",
    "#### 3. Scalability:\n",
    "- Enhance the scalability of the pipeline to handle larger datasets and more complex models. Implementing distributed computing techniques and leveraging cloud resources can help achieve this.\n",
    "\n",
    "#### 4. Robust Error Handling:\n",
    "- Implement robust error handling and logging mechanisms throughout the pipeline. This would ensure that any issues are promptly identified and addressed, improving the overall reliability of the system.\n",
    "\n",
    "#### 5. Continuous Monitoring and Evaluation:\n",
    "- Set up a continuous monitoring and evaluation framework to track the model's performance over time. This would help in identifying any degradation in performance and facilitate timely updates to the model.\n",
    "\n",
    "#### 6. Integration with C++:\n",
    "- Provide comprehensive documentation and support for integrating the model with C++ applications. This would make it easier for developers to deploy the model in production environments.\n",
    "\n",
    "#### 7. Security Enhancements:\n",
    "- Implement security measures to protect the model and data. This includes encryption of sensitive data, secure model deployment, and access control mechanisms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
